# Определение токсичных комментариев.

Для запуска нового сервиса интернет-магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 
Обучена модель классифицировать комментарии на позитивные и негативные. Проанализирован набор данных с разметкой о токсичности правок.
Построена модель со значением метрики качества F1 не меньше 0.75.
Текст лемматизирован с помощью WordNet + POS-теги, для векторизации использовался TF-IDF.

## Статус проекта
Завершен

## Общий вывод
Хорошую точность показала модель LGBM с F1-мерой 0.766, но ее обучение занимает некоторое время. Быстрее нее работает Логистическая Регрессия с F1 0.753.

Выбирать модель стоит исходя из требований к скорости работы. Рискну предположить, что для подобного проекта высокая скорость обучения не требуется, потому стоит выбрать LGBM.

## Описание данных

- text - содержит текст комментария
- toxic - целевой признак
